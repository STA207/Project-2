---
title: "Effects of Class Size on Math Performance in Tennessee"
output:
  pdf_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE)
```

```{r}
library("AER")
library("foreign")
library("sqldf")
library("plotly")
library("kableExtra")

```


```{r}
setwd("C:\\Users\\rosen_000\\Dropbox\\Daivs\\2-Winter Q 2020\\STA 207 Research Methods II\\Project-2")
star = read.spss("STAR_Students.sav",to.data.frame = TRUE)
```


```{r}
data1 = names(star) %in% c("g1tchid","g1classtype","g1schid","g1surban", "g1classsize","g1tmathss", "g1tgen")
data1 = star[,data1]
data1 = data1[complete.cases(data1),]
```


```{r}
#Group by teachers as unit
t_data1 = sqldf("SELECT DISTINCT(g1tchid) as g1_teachID,
                            g1schid as g1_schoolID,
                            g1classtype as g1_classtype,
                            g1surban as g1_surburban,
                            COUNT(g1tchid) as g1_classsize,
                            AVG(g1tmathss) as g1_avgmath,
                            MIN(g1tmathss) as g1_minmath,
                            MAX(g1tmathss) as g1_maxmath,
                            MEDIAN(g1tmathss) as g1_medmath
                    FROM data1
                    GROUP BY g1tchid")


t_data1$g1_teachID = as.factor(t_data1$g1_teachID)
t_data1$g1_schoolID = as.factor(t_data1$g1_schoolID)
t_data1$g1_classtype= as.factor(t_data1$g1_classtype)
t_data1$g1_surburban = as.factor(t_data1$g1_surburban)



write.csv(t_data1, "Teach_as_Unit.csv")
```



```{r}
#Boxplot of average class math scores broken by class type
box1 = plot_ly(t_data1, y = ~g1_avgmath, color = ~g1_classtype, type = "box") %>%
  layout(title = "Average Classroom Score",
         yaxis = list(title = "Classroom Average Sclaed Math Score"),
         xaxis = list(title = "Class Type"))

#Boxplot of min class math scores broken by class type
box2 = plot_ly(t_data1, y = ~g1_minmath, color = ~g1_classtype, type = "box") %>%
  layout(title = "Minimum Classroom Score",
         yaxis = list(title = "Classroom Minimum Sclaed Math Score"),
         xaxis = list(title = "Class Type")) 

#Boxplot of min class math scores broken by class type
box3 = plot_ly(t_data1, y = ~g1_maxmath, color = ~g1_classtype, type = "box") %>%
  layout(title = "Classroom Maximum Score",
         yaxis = list(title = "Sclaed Math Score"),
         xaxis = list(title = "Class Type"))

#Boxplot of med class math scores broken by class type
box4 = plot_ly(t_data1, y = ~g1_medmath, color = ~g1_classtype, type = "box") %>%
  layout(title = "Classroom Median Score",
         yaxis = list(title = "Sclaed Math Score"),
         xaxis = list(title = "Class Type"))
  
box1
box2
box3
box4
```


```{r}
#Histograms for Average Scores
a = sqldf("SELECT g1_avgmath FROM t_data1
          WHERE g1_classtype == 'SMALL CLASS'")

b = sqldf("SELECT g1_avgmath FROM t_data1
          WHERE g1_classtype  == 'REGULAR + AIDE CLASS'")

c = sqldf("SELECT g1_avgmath FROM t_data1
          WHERE g1_classtype == 'REGULAR CLASS'")

hist_avgsmall <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~a$g1_avgmath, marker = list(color = "#C6CFE5")) %>%
  layout(barmode = "overlay",
         title = "Class Average Scaled Math Score",
         xaxis = list(title = "SMALL CLASSES"))

hist_avgreg <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~b$g1_avgmath, marker = list(color = "#FDC6B0")) %>%
  layout(barmode = "overlay",
         title = "Class Average Scaled Math Score",
         xaxis = list(title = "REGULAR CLASSES"))

hist_avgregaide <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~c$g1_avgmath, marker = list(color = "#B2E0D2")) %>%
  layout(barmode = "overlay",
         title = "Class Average Scaled Math Score",
         xaxis = list(title = "REGULAR + AIDE CLASSES"))

hist_avgsmall
hist_avgreg
hist_avgregaide
```

```{r}
#Histograms for Average Scores
a = sqldf("SELECT g1_minmath FROM t_data1
          WHERE g1_classtype == 'SMALL CLASS'")

b = sqldf("SELECT g1_minmath FROM t_data1
          WHERE g1_classtype  == 'REGULAR + AIDE CLASS'")

c = sqldf("SELECT g1_minmath FROM t_data1
          WHERE g1_classtype == 'REGULAR CLASS'")

hist_minsmall <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~a$g1_minmath, marker = list(color = "#C6CFE5")) %>%
  layout(barmode = "overlay",
         title = "Class Minimum Scaled Math Score",
         xaxis = list(title = "SMALL CLASSES"))

hist_minreg <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~b$g1_minmath, marker = list(color = "#FDC6B0")) %>%
  layout(barmode = "overlay",
         title = "Class Minimum Scaled Math Score",
         xaxis = list(title = "REGULAR CLASSES"))

hist_minregaide <- plot_ly(alpha = 0.2) %>%
  add_histogram(x = ~c$g1_minmath, marker = list(color = "#B2E0D2")) %>%
  layout(barmode = "overlay",
         title = "Class Minimum Scaled Math Score",
         xaxis = list(title = "REGULAR + AIDE CLASSES"))

hist_minsmall
hist_minreg
hist_minregaide
```



```{r}
Lv_test_avg = leveneTest(g1_avgmath~g1_classtype, data = t_data1) #Equal Variacnes
kable(Lv_test_avg, caption = "Levene's Test for Equal Variance: Classroom Average Score") %>% kable_styling(bootstrap_options = "striped", full_width = F)

Lv_test_min = leveneTest(g1_avgmath~g1_classtype, data = t_data1) #Equal Variacnes
kable(Lv_test_min, caption = "Levene's Test for Equal Variance: Classroom Minimum Score") %>% kable_styling(bootstrap_options = "striped", full_width = F)
```



```{r}
#ANOVA

avg_anova = aov(g1_avgmath ~ g1_classtype + g1_schoolID + g1_classtype:g1_schoolID, 
                  data = t_data1)

summary(avg_anova)
plot(avg_anova) #normality is an issue


min_anova = aov(g1_minmath ~ g1_classtype + g1_schoolID + g1_classtype:g1_schoolID, 
                  data = t_data1)
summary(min_anova)
plot(min_anova) #normality is NOT an issue


med_anova = aov(g1_medmath ~ g1_classtype + g1_schoolID + g1_classtype:g1_schoolID, 
                  data = t_data1)
summary(med_anova)
plot(med_anova) #normality is NOT an issue
```


```{r, include=FALSE}
#Write Report
```

***

Team ID: 6

Name: Rongkui Han
Name: Connor Rosenberg
Name: Yuqing Yang
Name: Nassim Ali-Cahouche


# Introduction


## Background

The Student/Teacher Achievement Ratio (STAR) was a four-year longitudinal class-size study funded by the Tennessee General Assembly and conducted by the State Department of Education. Over 7,000 students from kindergarten to 3rd grade in 79 schools were randomly assigned into one of three interventions: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher's aide). Classroom teachers were also randomly assigned to the classes they would teach. The interventions were initiated as the students entered school in kindergarten and continued through third grade.    

The STAR experiment was designed by a group of researchers including Helen Pate-Bain, the driving force behind Project STAR, other academics, and members of the Tennessee Department of Education. Some of its key features are: 

1. *All Tennessee schools with K-3 classes were invited to participate.* Giving every school a chance to join the study helped ensure a diverse sample as well as rule out the possibility that class-size effects could be attributed to selection bias.   

2. *Each school included in the study had to have a large enough student body to form as least one of each of the three class types.* The within-school design provided built-in control for differences among schools in terms of resources, leadership, and facilities.   

3. *Schools from inner-city, urban, suburban and rural locations were included in the experiment.* This feature guaranteed that samples would include children from various ethnic backgrounds and income levels.   

4. *Students and teachers were randomly assigned to their class type.*    

5. *Investigators followed the standard procedures for confidentiality in human subjects' research.*   

6. *No children were to receive fewer services than normal because of the experiment.*    

7. *Student achievement was to be tracked by standarized tests, which were carefully monitored.*   


## Questions of Interest

To expand on our previous findings, we will set teachers as the experimental unit. Unlike our past research, which focused on the scores of an individual student, we will now consider the classroom median scaled math scores of each first-grade teacher.  The modified variable of interest will, in theory, stabilize the variability in our data and provide better conditions to make inferences about a teacher's performance. 

Our questions of interest are as follows:

1. Is there a significant difference in a first-grade teacher's median math scores across the three different class sizes?

2. Are teacher's performances relatively stable between different schools? That is, does the school itself affect class average math scores?

3. Does our ANOVA model fit well with the data? In other words, are the assumptions for anova satisfied? 

4. Can we conclude that class sizes affect the performacne of first-grade teachers?


## Population and study design

To expand on our previous findings, we will set teachers as the experimental unit. Unlike our past research, which focused on the scores of an individual student, we will now consider the average scaled math score of all students under each teacher.  The modified variable of interest will, in theory, stabilize the variability in our data and provide us with better conditions to make a causal statement as to the effect of class size on a teacher's performance. 

## Statistical Analysis

### Descriptive Analysis

> Task 1: Explore math scaled scores in the 1st with teachers as the unit. Generate summary statistics (in forms of tables or plots) that you find informative, and explain them.    


### Main Analysis

> Task 2: Write down a two-way ANOVA model to study the effects of class types on math scaled scores in 1st grade, with the school indicator as the other factor. Explain your notation.

> Task 3: Explain why your model is appropriate for this task on this data set. You may want to include statistics and plots in your explanation.    

### Sensitivity Analysis

# Results

## Descriptive Analysis

## Main Analysis

> Task 4: Fit the model you choose in Task 2 and show your fits in the report.    

> Task 5: Conduct model diagnostic and/or sensitivity analysis.

> Task 6: Test whether there is a difference in math scaled score in 1st grade across teachers in different class types. Justify your choice of test.

## Sensitivity analysis

# Discussion

> Task 7: Discuss whether you are able to make any causal statements based on your analysis.

> Task 8: Is there any difference between the results from Project 2 compared to the results from Project 1?

# Conclusions

1. Is there a significant difference in a first-grade teacher's average math scores across the three different class sizes?

2. Are teacher's performances relatively stable between different schools? That is, does the school itself affect class average math scores?

3. Does our ANOVA model fit well with the data? In other words, are the analysis of variance assumptions satisfied? 

4. Can we draw causal conclusion that class sizes affect the class average math scores of first-grade teachers?

